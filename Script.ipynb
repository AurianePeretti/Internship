{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1325ec6",
   "metadata": {},
   "source": [
    "## Choice of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be03b4",
   "metadata": {},
   "source": [
    "Dates columns removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49675fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_datetime_columns(df):# df parameter is a DataFrame\n",
    "    \n",
    "    dataframe_dates=df.select_dtypes(include=\"datetime\") # we select the columns whose type is 'datetime'\n",
    "    list_dates=df.select_dtypes(include=\"datetime\").columns.tolist()\n",
    "    print(\"The dates column-s removed are: \",list_dates,\"\\n\")\n",
    "    df.drop(labels=list_dates,axis=1,inplace=True) # we delete the 'datetime' columns in our dataset\n",
    "    \n",
    "    return dataframe_dates # returns the DataFrame with the 'datetime' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9dab41",
   "metadata": {},
   "source": [
    "Columns choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b036fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_choice(df): # df parameter is a DataFrame\n",
    "    \n",
    "    cols=df.columns.tolist()\n",
    "    lst=[]\n",
    "    for column in cols:\n",
    "        # we delete the columns which have no data or whose number of groups is over 90% of the total rows of the dataset\n",
    "            if (df.groupby(by=column).ngroups==0) or (df.groupby(by=column).ngroups>(0.9*df.shape[0])):\n",
    "                lst.append(column)\n",
    "                df=df.drop(labels=column,axis=1)\n",
    "    print(\"The column-s definitely deleted are: \",lst,\"\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78678759",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3a86f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_missing_data(df): # df parameter is a DataFrame\n",
    "    print(\"Number of missing data: \\n\")\n",
    "    print(df.isnull().sum()) # displays the number of missing data for each column\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "384b8843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_of_missing_data(df): # df parameter is a DataFrame\n",
    "    plt.figure()\n",
    "    missingno.matrix(df) # displays visually the missing data in each column of df\n",
    "    plt.title(label=\"Missing data in the dataset\",fontdict={'fontsize':40})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83cb0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_missing_data_string_columns(df): # df parameter is a DataFrame\n",
    "    \n",
    "    df_object=df.select_dtypes(include=\"object\").copy() # we only select the 'object' columns\n",
    "    cols=df_object.columns.tolist()\n",
    "    list_cols_processed=[]\n",
    "    \n",
    "    for col in cols:\n",
    "        \n",
    "        if df_object[col].isnull().any()==True: # we check if there are any missing data in col column\n",
    "            list_cols_processed.append(col)\n",
    "            \n",
    "            if df_object.groupby(by=col).ngroups==1:# if there is just a single type of data in col column, we will replace the missing data by this type\n",
    "                df[col].fillna(value=df[col][0],inplace=True) # we consider that we didn't delete the rows at this point\n",
    "            \n",
    "            else:\n",
    "                df[col].fillna(value=\"Unknown\",inplace=True) # we replace the missing data by \"Unknown\"\n",
    "    print(\"The string columns which were processed for having missing data are:\\n\\n\",list_cols_processed,\"\\n\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02613ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_miss_data_num(df): # df parameter is a DataFrame\n",
    "    \n",
    "    cols=df.select_dtypes(include=np.number).columns.tolist() # we only select the numeric columns\n",
    "    lst=[]\n",
    "    for i in range(len(cols)):\n",
    "        \n",
    "        if df[cols[i]].isnull().any()==True: # we check if there are any missing data in col column\n",
    "            lst.append(cols[i])\n",
    "            if df.groupby(by=cols[i]).ngroups==1: # if there is just a single type of data in col column, we will replace the missing data by this type\n",
    "                df[cols[i]].fillna(value=df[cols[i]][0],inplace=True) # we consider that we didn't delete the rows at this point\n",
    "            else:\n",
    "                df[cols[i]].fillna(value=0,inplace=True) # we replace the missing data by 0 because we saw that in all the datasets there weren't any missing data for the identifier numeric columns\n",
    "    print(\"The numeric columns which were processed for having missing data are: \\n\")\n",
    "    print(lst,\"\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "531cedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_columns_outliers(df): # df parameter is a DataFrame\n",
    "    \n",
    "    df_num=df.select_dtypes(include=np.number)\n",
    "    for col in df_num.columns.tolist():\n",
    "        \n",
    "        if df_num[df_num[col]<0].empty:\n",
    "            print(col,\": only POSITIVE values\",\"\\n\")\n",
    "        else:\n",
    "            print(col,\"some NEGATIVE values\",\"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b4742",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d0315c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(df): # the parameter is a DataFrame\n",
    "    print(\"Statistics of the dataset:\",\"\\n\")\n",
    "    print(df.describe()) # displays all the statistic characteristics of the numeric columns\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bcdc46",
   "metadata": {},
   "source": [
    "## Convertion from categoric to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aab1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_num(df):\n",
    "    df_num=df.copy()\n",
    "    dft=df.copy()\n",
    "    dft.reset_index(drop=True, inplace=True) # we reset the index because the previous point may have deleted some rows\n",
    "    cols=df.columns.tolist()\n",
    "    ord_enc = OrdinalEncoder()\n",
    "    lst=[]\n",
    "    for i in range(len(cols)):\n",
    "        if type(dft[cols[i]][0])==str:\n",
    "            if (df.groupby(by=cols[i]).ngroups < (0.9*df.shape[0])):\n",
    "                print(cols[i],\"\\n\")\n",
    "                lst.append(cols[i])\n",
    "                df_num[cols[i]]=ord_enc.fit_transform(df_num[[cols[i]]]) \n",
    "    print(\"The column-s converted to numeric are:\",\"\\n\")\n",
    "    print(lst,\"\\n\")\n",
    "    return df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04db78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_num_2(df):\n",
    "    df_num=df.copy()\n",
    "    dft=df.copy()\n",
    "    dft.reset_index(drop=True, inplace=True) # we reset the index because the previous point may have deleted some rows\n",
    "    cols=df.columns.tolist()\n",
    "    ord_enc = OrdinalEncoder()\n",
    "    \n",
    "    lst=[]\n",
    "    for col in cols:\n",
    "        if type(dft[col][0])==str:\n",
    "            \n",
    "            if (df.groupby(by=col).ngroups < (0.9*df.shape[0])):\n",
    "                \n",
    "                df_num[col]=df_num[col].astype(str)\n",
    "                lst.append(col)\n",
    "\n",
    "                df_num[col]=ord_enc.fit_transform(df_num[[col]]) \n",
    "    print(\"The column-s converted to numeric are:\",\"\\n\")\n",
    "    print(lst,\"\\n\")\n",
    "    return df_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd0113b",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b26d5",
   "metadata": {},
   "source": [
    "Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1d05e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df,height=16,width=16): # the df parameter is a dataframe\n",
    "    \n",
    "    plt.figure(figsize=(height,width))\n",
    "    correlation_matrix=df.corr(method=\"pearson\") # calculates the correlation matrix thanks to Pearson method\n",
    "    correlation_matrix=np.round(correlation_matrix,2)\n",
    "    sns.heatmap(correlation_matrix,square=True,annot=True,annot_kws={'size':15}) # displays the correlation matrix with a heatmap\n",
    "    plt.title(label=\"Correlation Matrix\",fontdict={'fontsize':40})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c793d0",
   "metadata": {},
   "source": [
    "Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cedfd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(df):# the parameter is a DataFrame\n",
    "    \n",
    "    lst=df.columns.tolist() # we will display the histograms for all the columns of the DataFrame\n",
    "    fig, ax=plt.subplots(nrows=len(lst),ncols=1,figsize=(10,60))\n",
    "    \n",
    "    \n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        sns.histplot(df[lst[i]],kde=True, ax = ax) # displays the histogram of the column\n",
    "        #print(\"The skewness of this variable is :\",df[lst[i]].skew(),\"\\n\")\n",
    "        #print(\"The kurtosis of this variable is :\",df[lst[i]].kurt(),\"\\n\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5b25a",
   "metadata": {},
   "source": [
    "Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ac6eb125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_scatter_plots(df): # the parameter is a DataFrame\n",
    "    \n",
    "    plt.figure(figsize=(60,60))\n",
    "    g = sns.pairplot(df.select_dtypes(exclude=bool),height=3) # displays all the scatter plots between the columns and the histograms on the diagonal\n",
    "    g.fig.suptitle(\"Scatter Plots and Histograms\",fontsize=100,y=1) # y= some height>1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555e57b",
   "metadata": {},
   "source": [
    "Box plots categoric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b2c181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot_cat(df,var,height=15,width=15):\n",
    "    \n",
    "    sns.set_theme()\n",
    "    f, ax=plt.subplots(figsize=(width,height))\n",
    "    \n",
    "    list_col=df.select_dtypes(include=np.number).columns.tolist()\n",
    "    \n",
    "    for i in range(len(list_col)):\n",
    "        plt.subplot(len(list_col),1,i+1)\n",
    "        sns.boxplot(x=var,y=list_col[i],data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47b820d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_box_plot_cat(df,height=15,width=15):\n",
    "    lst=df.select_dtypes(include=\"object\")\n",
    "    for col in lst:\n",
    "        box_plot_cat(df,col,height,width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1d5e4",
   "metadata": {},
   "source": [
    "Boxplots numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "185afe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentages_outliers(df,var): # df parameter is a DataFrame, var parameter is the name of the column (string)\n",
    "    \n",
    "    if df[(df[var]>100)|(df[var]<0)].any().sum()!=0: # we check if there are some values over 100 or less than 0\n",
    "        print(\"Error of percentages for \",var,\"in these rows \\n\")\n",
    "        dh=df[(df[var]>100)|(df[var]<0)].copy()\n",
    "        print(dh[df.columns.tolist()[0]],\"\\n\") # we print the data of the first column to give a reference to the client after\n",
    "    else:\n",
    "        print(\"No outliers for \",var,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94cd1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def like_boxplot_numeric(df,var,lower_limit=None,upper_limit=None): \n",
    "    # if there are any values under lower_limit they will be considered as outliers\n",
    "    # if there are any values over upper_limit they will be considered as outliers\n",
    "    # it is named like boxplot because it seems to be a boxplot but it is not because we do an interpolation \n",
    "    whis1 = np.interp([lower_limit,upper_limit], np.sort(df[var]), np.linspace(0,1,df[var].size)) * 100 # we need to do an interpolation otherwise we can't display clearly the whiskers we want\n",
    "    fig,ax=plt.subplots()\n",
    "    ax.set_title(f\"Visualization of {var}\")\n",
    "    ax.boxplot(df[var],whis=whis1)\n",
    "    plt.show()\n",
    "    percentages_outliers(df,var) # this function will display percentage outliers if there are any in var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentages_columns(df,n):# the df parameter is a DataFrame, the n parameter is an integer and it's the number of the dataset\n",
    "    # the choice of parameter n is important because not all the datasets have percentage columns\n",
    "    cols=df.select_dtypes(include=np.number).columns.tolist()\n",
    "    if n==1:\n",
    "        for i in range(len(cols)-5,len(cols)-1,1):\n",
    "            like_boxplot_numeric(df,cols[i],lower_limit=0,upper_limit=100)\n",
    "            # displays like_boxplot for each percentage columns\n",
    "    elif n==6:\n",
    "        for i in range(len(cols)-5,len(cols),1):\n",
    "            like_boxplot_numeric(df,cols[i],lower_limit=0,upper_limit=100)\n",
    "            # displays like_boxplot for each percentage columns\n",
    "    else:\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be0d41",
   "metadata": {},
   "source": [
    "## Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e09c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(df,dates): # df parameter is a DataFrame, dates parameter is DataFrame\n",
    "    return pd.concat([dates,df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d517ac",
   "metadata": {},
   "source": [
    "## Deleting IQR outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b973a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df,n):# df parameter is a DataFrame, n parameter is an integer and is the number of the dataset\n",
    "    # we decided to apply remove_outliers_iqr function on some specific columns in each dataset\n",
    "    # these columns are all numeric and aren't identifier columns, otherwise it doesn't make any sense to apply this function\n",
    "    # on identifier columns.\n",
    "    if n==1:\n",
    "        return remove_outliers_iqr(df,['Total Meat Block Qty', 'Target Fat %', 'Moisture %', 'Fat %', 'Protein %', 'Collagen'] )\n",
    "    elif n==2:\n",
    "        return remove_outliers_iqr(df,['Net Weight', 'Tare'])\n",
    "    elif n==3:\n",
    "        return remove_outliers_iqr(df,['Net Weight', 'Tare'])\n",
    "    elif n==4:\n",
    "        return remove_outliers_iqr(df,['Net Weight', 'Tare'])\n",
    "    elif n==5:\n",
    "        return remove_outliers_iqr(df,['Net Weight', 'Tare'])\n",
    "    elif n==6:\n",
    "        return remove_outliers_iqr(df,['Protein', 'Fat', 'Moisture', 'Ash', 'Salt'])\n",
    "    else:\n",
    "        print(\"The taped number is not correct \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a90fb677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df,cols): # df parameter is a DataFrame, cols parameter is a list which contained some columns names of the dataset\n",
    "    \n",
    "    df_temp=df[cols].copy()\n",
    "    Q1 = df_temp.quantile(0.25) # first quartile\n",
    "    Q3 = df_temp.quantile(0.75) # third quartile\n",
    "    IQR = Q3 - Q1 # interquartile\n",
    "    idx = ((df_temp < (Q1 - 1.5 * IQR)) | (df_temp > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    # we consider as outlier the values which are lower than Q1 - 1.5*IQR and the values which exceed Q3 + 1.5*IQR\n",
    "    df_temp.insert(1,\"Outliers\",idx)\n",
    "    df.drop(df_temp.loc[df_temp[\"Outliers\"]==True].index,inplace=True) # we delete the outliers in the DataFrame\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6371d936",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb9b279",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424fad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eec6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importation_data():\n",
    "    return pd.ExcelFile(\"ERPData.xlsx\") #we import the desired excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a80772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importation_dataset(data,number): # the data parameter is the Excel file with all datasets, the number parameter is the number choosen to have the desired dataset\n",
    "    #as there are six datasets, number goes from 1 to 6\n",
    "    print(\"Name of the imported dataset: \",data.sheet_names[number],\"\\n\")\n",
    "    return pd.read_excel(data,data.sheet_names[number]) # the argument number chooses the dataset we want in sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "759f1fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_dataset(df):\n",
    "    pd.set_option('display.max_columns',df.shape[1]+1) # we display all the columns\n",
    "    print(\"Visualization of the dataset: \\n\")\n",
    "    print(df.head(3))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bed6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_dataset(df):\n",
    "    print(\"Number of rows: \",df.shape[0],\"\\n\")\n",
    "    print(\"Number of columns: \",df.shape[1],\"\\n\")\n",
    "    df.info(verbose=True)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
